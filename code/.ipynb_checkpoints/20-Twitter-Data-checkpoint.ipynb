{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Data Collection & Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we're going to learn how to analyze and explore Twitter data with the Python/command line tool [twarc](https://twarc-project.readthedocs.io/en/latest/). We're specifically going to work with [twarc2](https://twarc-project.readthedocs.io/en/latest/twarc2/), which is designed for version 2 of the Twitter API (released in 2020) and the Academic Research track of the Twitter API (released in 2021), which enables researchers to collect tweets from the entire Twitter archive for free.\n",
    "\n",
    "Twarc was developed by a project called [Documenting the Now](https://www.docnow.io/). The DocNow team develops tools and ethical frameworks for social media research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote class=\"epigraph\" style=\" padding: 10px\">\n",
    "    \n",
    "[David Foster Wallace]...has become lit-bro shorthand...Make a passing reference to the “David Foster Wallace fanboy” and you can assume the reader knows whom you’re talking about.<p class =\"attribution\">—Molly Fischer,\n",
    "<a href=\"https://slate.com/culture/2015/08/men-who-love-david-foster-wallace-what-s-wrong-with-bros-obsessing-over-infinite-jest.html\">\"David Foster Wallace, Beloved Author of Bros\"</a>\n",
    "    </p>\n",
    "    \n",
    "</blockquote>\n",
    "\n",
    "![](https://static01.nyt.com/images/2014/12/18/arts/18book-sub/BOOK-1418838418938-superJumbo.jpg?quality=90&auto=webp)\n",
    "*Source: [Giovanni Giovanetti, NYT](https://www.nytimes.com/2014/12/18/books/the-david-foster-wallace-reader-a-compilation.html)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Twitter conversation that we're going to explore in this lesson is related to \"Wallace bros\" — fans of the author David Foster Wallace who are often described as \"bros\" or, more pointedly, \"David Foster Wallace bros.\"\n",
    "\n",
    "For example, in *Slate* in 2015, Molly Fischer argued that David Foster Wallace's writing — most famously his novel *Infinite Jest* — tended to attract  [a fan base of chauvinistic and misogynistic young men](https://slate.com/culture/2015/08/men-who-love-david-foster-wallace-what-s-wrong-with-bros-obsessing-over-infinite-jest.html). But other people  have defended Wallace's fans and the author against such charges. What is a \"David Foster Wallace bro\"? Was DFW himself a \"bro\"? Who is using this phrase, how often are they using it, and why? We're going to track this phrase and explore the varied viewpoints in this cultural conversation by analyzing tweets that mention \"David Foster Wallace bro.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Queries & Privacy Concerns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To collect tweets from the Twitter API, we need to make queries, or requests for specific kinds of tweets — e.g., `twarc2 search *query*`. The simplest kind of query is a keyword search, such as the phrase \"David Foster Wallace bro,\" which should return any tweet that contains all of these words in any order — `twarc2 search \"David Foster Wallace bro\"`.\n",
    "\n",
    "There are many other operators that we can add to a query, which would allow us to collect tweets only from specific Twitter users or locations, or to only collect tweets that meet certain conditions, such as containing an image or being authored by a verified Twitter user. Here's an excerpted table of search operators taken from [Twitter's documentation](https://developer.twitter.com/en/docs/twitter-api/tweets/search/integrate/build-a-query#list) about how to build a search query. There are many other operators beyond those included in this table, and I recommend reading through [Twitter's entire web page on this subject](https://developer.twitter.com/en/docs/twitter-api/tweets/search/integrate/build-a-query#list).\n",
    "\n",
    "\n",
    "| Search Operator             | Explanation                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
    "|:--------------------:|:----------------------------------------------------------------------------------------------:|\n",
    "| keyword              | Matches a keyword within the body of a Tweet. `so sweet and so cold`                                                                                          \n",
    "| \"exact phrase match\" | Matches the exact phrase within the body of a Tweet. `\"so sweet and so cold\" OR \"plums in the icebox\"`                                                                                              |\n",
    "| - | Do NOT match a keyword or operator `baldwin -alec`, `walt whitman -bridge`                                                                                              |\n",
    "| #                    | Matches any Tweet containing a recognized hashtag `#arthistory`        |                                                                             |\n",
    "| from:, to:                | Matches any Tweet from or to a specific user. `from:KingJames` `to:KingJames`                                                                    |                                                                                                            |\n",
    "| place:               | Matches Tweets tagged with the specified location or Twitter place ID. `place:\"new york city\" OR place:seattle`                                                                                            |\n",
    "| is:reply, is:quote             | Returns only replies or quote tweets. `DFW bro is:reply` `David Foster Wallace bro is:quote`                                                                                                                               |\n",
    "| is:verified          | Returns only Tweets whose authors are verified by Twitter.`DFW bro is:verified`                                                                                                                                |\n",
    "| has:media           | Matches Tweets that contain a media object, such as a photo, GIF, or video, as determined by Twitter. `I Think You Should Leave has:media`                                                                                                                                |\n",
    "| has:images, has:videos           | Matches Tweets that contain a recognized URL to an image. `i'm gonna tell my kinds that this was has:images`                                                                                    |\n",
    "| has:geo              | Matches Tweets that have Tweet-specific geolocation data provided by the Twitter user.  `pyramids has:geo`              \n",
    "\n",
    "In this lesson, we will only be collecting tweets that were tweeted by verified users: `\"David Foster Wallace bro is:verified\"`.\n",
    "\n",
    "As I discussed in [\"Users’ Data: Legal & Ethical Considerations,\"](01-User-Ethics-Legal-Concerns) collecting publicly available tweets is legal, but it still raises a lot of privacy concerns and ethical quandaries — particularly when you re-publish user's data, as I am in this lesson. To reduce potential harm to Twitter users when re-publishing or citing tweets, it can be helpful to ask for explicit permission from the authors or to focus on tweets that have already been reasonably exposed to the public (e.g., tweets with many retweets or tweets from verified users), such that re-publishing the content will not unduly increase risk to the user.\n",
    "               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because twarc relies on Twitter's API, we need to apply for a Twitter developer account and create a Twitter application before we can use it. You can find instructions for the application process in [\"Twitter API Set Up.\"](11-Twitter-API-Setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you haven't done so already, you need to install twarc and configure twarc with your bearer token and/or API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T15:32:39.424764Z",
     "start_time": "2022-11-07T15:32:39.419379Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install twarc\n",
    "#!twarc2 configure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make an interactive plot, we're also going to install the package plotly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T15:32:42.628302Z",
     "start_time": "2022-11-07T15:32:40.157351Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (5.10.0)\r\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from plotly) (8.1.0)\r\n"
     ]
    }
   ],
   "source": [
    "# !pip install plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we're going to import plotly as well as pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T15:32:49.706387Z",
     "start_time": "2022-11-07T15:32:49.700585Z"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 400\n",
    "pd.options.display.max_columns = 90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Tweet Counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we're going to do is retrieve \"tweet counts\" — that is, retrieve the number of tweets that included the phrase \"David Foster Wallace bro\" each day in Twitter's history.\n",
    "\n",
    "The [tweet counts API endpoint](https://twittercommunity.com/t/introducing-new-tweet-counts-endpoints-to-the-twitter-api-v2/155997) is a convenient feature of the v2 API (first introduced in 2021) that allows us to get a sense of how many tweets will be returned for a given query before we actually collect all the tweets that match the query. We won't get the text of the tweets or the users who tweeted the tweets or any other relevant data. We will simply get the number of tweets that match the query. This is helpful because we might be able to see that the search query \"Wallace\" matches too many tweets, which would encourage us to narrow our search by modifying the query. \n",
    "\n",
    "The tweet counts API endpoint is perhaps even more useful for research projects that are primarily interested in tracking the volume of a Twitter conversation over time. In this case, tweet counts enable a researcher to retrieve this information in a way that's faster and easier than retrieving all tweets and relevant metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get tweet counts from Twitter's entire history with twarc2, we will use [`twarc2 counts`](https://twarc-project.readthedocs.io/en/latest/twarc2/#counts) followed by a search query.\n",
    "\n",
    "We will also use the flag `--csv` because we want to output the data as a CSV, the flag `--archive` because we're working with the Academic Research track of the Twitter API and want access to the full archive, and the flag `--granularity day` to get tweet counts per day (other options include `hour` and `minute` — you can see more in [twarc's documentation](https://twarc-project.readthedocs.io/en/latest/twarc2/#counts)).  Finally, we write the data to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T15:32:51.249336Z",
     "start_time": "2022-11-07T15:32:51.244748Z"
    }
   },
   "outputs": [],
   "source": [
    "# !twarc2 counts \"David Foster Wallace bro is:verified\" --csv --archive --granularity day > twitter-data/tweet-counts.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can read in this CSV file with pandas, parse the date columns, and sort from earliest to latest. The code below is largely [borrowed from Ed Summers](https://github.com/edsu/notebooks/blob/master/Black%20Lives%20Matter%20Counts.ipynb). Thanks, Ed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition pandasreview\" name=\"html-admonition\" style=\"background: black; color: white; padding: 10px\">\n",
    "<p class=\"title\">Pandas</p>\n",
    " Do you need a refresher or introduction to the Python data analysis library Pandas? Be sure to check out <a href=\"https://melaniewalsh.github.io/Intro-Cultural-Analytics/Data-Analysis/Pandas-Basics-Part1.html\"> Pandas Basics (1-3) </a> in this textbook!\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T15:32:52.804092Z",
     "start_time": "2022-11-07T15:32:52.797353Z"
    }
   },
   "outputs": [],
   "source": [
    "# Code borrowed from Ed Summers\n",
    "# https://github.com/edsu/notebooks/blob/master/Black%20Lives%20Matter%20Counts.ipynb\n",
    "\n",
    "# Read in CSV as DataFrame\n",
    "# tweet_counts_df = pd.read_csv('twitter-data/tweet-counts.csv', parse_dates=['start', 'end'])\n",
    "# Sort values by earliest date\n",
    "# tweet_counts_df = tweet_counts_df.sort_values('start')\n",
    "# tweet_counts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can make a quick plot of tweets per day with [plotly](https://plotly.com/python/line-charts/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T15:32:53.826173Z",
     "start_time": "2022-11-07T15:32:53.820572Z"
    }
   },
   "outputs": [],
   "source": [
    "# Code borrowed from Ed Summers\n",
    "# https://github.com/edsu/notebooks/blob/master/Black%20Lives%20Matter%20Counts.ipynb\n",
    "# Make a line plot from the DataFrame and specify x and y axes, axes titles, and plot title\n",
    "# figure = px.line(tweet_counts_df, x='start', y='day_count',\n",
    "#     labels={'start': 'Time', 'day_count': 'Tweets per Day'},\n",
    "#     title= 'DFW Bro Tweets'\n",
    "# )\n",
    "\n",
    "# figure.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a plotly line chart, we can hover over points to see more information, and we can use the tool bar in the upper right corner to zoom or pan on different parts of the graph. We can also press the camera button to download an image of the graph at any pan or zoom level.\n",
    "\n",
    "To return to the original view, double-click on the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Tweets (Standard Track)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To actually collect tweets and their associated metadata, we can use the command `twarc2 search` and insert a query.\n",
    "\n",
    "Here we're going to search for any tweets that mention the words \"David Foster Wallace bro\" and were tweeted by verified accounts *in the past week*. By default, `twarc2 search` will use the standard track of the Twitter API, which only collects tweets from the past week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T15:32:54.860952Z",
     "start_time": "2022-11-07T15:32:54.856395Z"
    },
    "scrolled": true,
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [],
   "source": [
    "# !twarc2 search \"David Foster Wallace is:verified\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/melaniewalsh/Intro-Cultural-AnalyticsThe tweets and tweet metadata above are being printed to the notebook. But we want to save this information to a file so we can work with it.\n",
    "\n",
    "To output Twitter data to a file, we can also include a filename with the \".jsonl\" file extension, which stands for JSON lines, a special kind of JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T15:32:56.027360Z",
     "start_time": "2022-11-07T15:32:56.021313Z"
    }
   },
   "outputs": [],
   "source": [
    "# !twarc2 search \"David Foster Wallace is:verified\" twitter-data/dfw_last_week.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theoretically, a tweet with \"David,\" \"Foster\", and \"Wallace\" in different places would be matched by the more general search above. If we wanted to match the words \"David Foster Wallace\" exactly, we would need to put \"David Foster Wallace\" in quotation marks *and* \"escape\" those quotation marks, so that `twarc2` will know that our query shouldn't end at the next quotation mark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T15:33:14.727512Z",
     "start_time": "2022-11-07T15:33:14.725225Z"
    }
   },
   "outputs": [],
   "source": [
    "# !twarc2 search \"\\\"David Foster Wallace\\\" is:verified\" twitter-data/dfw_exact.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're working on a Mac, you should be able to escape the quotation marks with backslashes `\\` before the characters, as shown in the example above. But if you're working on a Windows computer, you may need to use triple quotations instead, for example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`twarc2 search \"\"\" \"David Foster Wallace\" is:verified\"\"\" twitter-data/dfw_exact.jsonl`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Tweets (Academic Track, Full Twitter Archive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"admonition attention\" name=\"html-admonition\" style=\"background: lightyellow; padding: 10px\">\n",
    "<p class=\"title\">Attention</p>\n",
    "Remember that this functionality is only available to those who have an [Academic Research account](https://developer.twitter.com/en/products/twitter-api/academic-research).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To collect tweets from Twitter's entire historical archive, we need to add the `--archive` flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T15:33:14.736061Z",
     "start_time": "2022-11-07T15:33:14.733974Z"
    }
   },
   "outputs": [],
   "source": [
    "# !twarc2 search \"David Foster Wallace bro is:verified\" --archive twitter-data/dfw_bro.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert JSONL to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make our Twitter data easier to work with, we can convert our JSONL file to a CSV file with the [`twarc-csv`](https://pypi.org/project/twarc-csv/) plugin, which needs to be installed separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T15:33:18.135317Z",
     "start_time": "2022-11-07T15:33:18.132310Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install twarc-csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once installed, we can use the plug-in from twarc2 with the input filename for the JSONL and a desired output filename for the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T15:33:18.941017Z",
     "start_time": "2022-11-07T15:33:18.934936Z"
    }
   },
   "outputs": [],
   "source": [
    "# !twarc2 csv twitter-data/dfw_bro.jsonl twitter-data/dfw_bro.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, when converting from the JSONL file, `twarc-csv` will only include tweets that were directly returned from the search.\n",
    "\n",
    "If you want you can also use `--inline-referenced-tweets` option to make \"referenced\" tweets into their own rows in the CSV file. For example, if a quote tweet matched our query, the tweet being quoted would also be included in the CSV file as its own row, even if it didn't match our query. But as of v0.5.0 of twarc-csv this is no longer the default behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to explore the data!\n",
    "\n",
    "To work with our tweet data, we can read in our CSV file with pandas and again parse the date column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T15:33:19.973898Z",
     "start_time": "2022-11-07T15:33:19.969084Z"
    }
   },
   "outputs": [],
   "source": [
    "# tweets_df = pd.read_csv('twitter-data/dfw_bro.csv',\n",
    "#                         parse_dates = ['created_at'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we scroll through this dataset, we can see that there are only 29 tweets that matched our search query, but there is a *lot* of metadata associated with each tweet. Scroll to the right to see all the information. What category surprises you the most? (For me, it's the tweet author's pinned tweet from their own timeline. Your pinned tweet gets attached to everything else you tweet!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T15:33:20.911175Z",
     "start_time": "2022-11-07T15:33:20.906749Z"
    },
    "scrolled": true,
    "tags": [
     "output_scroll",
     "full-width"
    ]
   },
   "outputs": [],
   "source": [
    "# tweets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we ask for a list of all the columns in the DataFrame, we can see that there are more than 90 columns here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T15:33:25.889561Z",
     "start_time": "2022-11-07T15:33:25.884789Z"
    },
    "scrolled": true,
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [],
   "source": [
    "# tweets_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you experiment with the query syntax provided by the Twitter API you should make a habit of scanning through your collected Twitter data to ensure that your API query and subsequent manipulations are returning the data that you expect and want. If you notice tweets you don't expect return to examine your query to see if you can explain why those tweets are turning up. If you can't find an adequate explanation you might want to ask in the [Twitter Community Forum](https://twittercommunity.com)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Tweet and Media URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make some Python functions that will create a tweet URL based on each tweet's unique ID as well as extract an image URL if one exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T15:33:26.685505Z",
     "start_time": "2022-11-07T15:33:26.672283Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make Tweet URL\n",
    "def make_tweet_url(tweets):\n",
    "    # Get username\n",
    "    username = tweets[0]\n",
    "    # Get tweet ID\n",
    "    tweet_id = tweets[1]\n",
    "    # Make tweet URL\n",
    "    tweet_url = f\"https://twitter.com/{username}/status/{tweet_id}\"\n",
    "    return tweet_url\n",
    "\n",
    "# Extract Image URL\n",
    "from ast import literal_eval\n",
    "def get_image_url(media):\n",
    "    # if not NaN or {}\n",
    "    if type(media) != float and media != '{}':\n",
    "        # Convert to an actual Python list, not just a string\n",
    "        media =  literal_eval(media)\n",
    "        media = media[0]\n",
    "         # Extract media url if it exists\n",
    "        if 'url' in media.keys():\n",
    "            return media['url']\n",
    "    else:\n",
    "        return \"No Image URL\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we apply the above Python functions to the relevant columns to create new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T15:33:27.665155Z",
     "start_time": "2022-11-07T15:33:27.659390Z"
    }
   },
   "outputs": [],
   "source": [
    "# tweets_df['tweet_url'] = tweets_df[['author.username', 'id']].apply(make_tweet_url, axis='columns')\n",
    "# tweets_df['media'] = tweets_df['attachments.media'].apply(get_image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename and Select Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the data more readable, we're going to rename a number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T15:33:28.752283Z",
     "start_time": "2022-11-07T15:33:28.745278Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tweets_df.rename(columns={'created_at': 'date',\n",
    "#                           'public_metrics.retweet_count': 'retweets', \n",
    "#                           'author.username': 'username', \n",
    "#                           'author.name': 'name',\n",
    "#                           'author.verified': 'verified', \n",
    "#                           'public_metrics.like_count': 'likes', \n",
    "#                           'public_metrics.quote_count': 'quotes', \n",
    "#                           'public_metrics.reply_count': 'replies',\n",
    "#                            'author.description': 'user_bio'},\n",
    "#                             inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we're only going to select the columns that we're interested. Depending on your project and research question, you should change and customize these categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T15:33:29.516229Z",
     "start_time": "2022-11-07T15:33:29.513335Z"
    }
   },
   "outputs": [],
   "source": [
    "# tweets_df = tweets_df[['date', 'username', 'name', 'verified', 'text', 'retweets',\n",
    "#            'likes', 'replies',  'quotes', 'tweet_url', 'media', 'user_bio']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can view our more focused DataFrame!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T15:33:30.086443Z",
     "start_time": "2022-11-07T15:33:30.081054Z"
    },
    "scrolled": true,
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [],
   "source": [
    "# tweets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort By Top Retweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can sort by number of retweets to see the most circulated tweets. Let's examine the top 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T15:33:31.403803Z",
     "start_time": "2022-11-07T15:33:31.398499Z"
    },
    "scrolled": true,
    "tags": [
     "full-width"
    ]
   },
   "outputs": [],
   "source": [
    "# tweets_df.sort_values(by='retweets', ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the most retweeted tweet in this dataset:\n",
    "\n",
    "<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">david foster wallace bro conversation again? i feel like by this point in the discourse i need footnotes! (just a little &quot;insider&quot; dfw humor for ya)</p>&mdash; David Grossman (@davidgross_man) <a href=\"https://twitter.com/davidgross_man/status/1297936487909130240?ref_src=twsrc%5Etfw\">August 24, 2020</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort By Date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can sort from the earliest tweets to the latest tweets. Let's examine the earliest 5 tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T15:33:32.312358Z",
     "start_time": "2022-11-07T15:33:32.307795Z"
    },
    "scrolled": true,
    "tags": [
     "full-width"
    ]
   },
   "outputs": [],
   "source": [
    "# tweets_df.sort_values(by='date', ascending=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The earliest tweet in this dataset is from the music label Melodic Records:\n",
    "\n",
    "<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\"><a href=\"https://twitter.com/MelodicRecords?ref_src=twsrc%5Etfw\">@MelodicRecords</a> chillax brother, we all gud. Put another blunt on the barbie &#39;n&#39; go wid th&#39; flo bro. Dude man... <a href=\"http://t.co/q0RUmv12\">http://t.co/q0RUmv12</a></p>&mdash; Drowned in Sound ⚓️ (@DrownedinSound) <a href=\"https://twitter.com/DrownedinSound/status/146330510422048768?ref_src=twsrc%5Etfw\">December 12, 2011</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Tweets Over Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An easy way to create a plot of tweets over time is to add a column with a 1 for every row, which we can use to count how many tweets were published per day, week, month, or year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T15:33:33.286033Z",
     "start_time": "2022-11-07T15:33:33.280704Z"
    }
   },
   "outputs": [],
   "source": [
    "# tweets_df = tweets_df.assign(count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to set the date column to the index so we can do some special date manipulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T15:33:33.733916Z",
     "start_time": "2022-11-07T15:33:33.728369Z"
    },
    "scrolled": true,
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [],
   "source": [
    "# tweets_df = tweets_df.set_index('date')\n",
    "# tweets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because our index is a datetime value, we can use the special Pandas method [`.resample()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.resample.html) to group the tweets by month, add them up, and plot them over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T15:33:34.262440Z",
     "start_time": "2022-11-07T15:33:34.257280Z"
    }
   },
   "outputs": [],
   "source": [
    "# tweets_df['count'].resample('M').sum()\\\n",
    "# .plot(title='\"David Foster Wallace Bro\"\\n Tweets from Verified Accounts');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Links and Images in Twitter Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display links and images in our DataFrame, we can convert the image URL into an HTML image tag, and we can display our DataFrame as an HTML object with the `HTML` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T15:33:35.336334Z",
     "start_time": "2022-11-07T15:33:35.327816Z"
    },
    "scrolled": true,
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "def get_image_html(link):\n",
    "    # check to see if the media category has an image URL\n",
    "    if link != \"No Image URL\":\n",
    "        # format the image url as an HTML image\n",
    "        image_html = f\"<a href='{link}'>'<img src='{link}' width='500px'></a>                            \"\n",
    "        return image_html\n",
    "    else:\n",
    "        return \"No Image URL\"\n",
    "# Apply the above function to the media column\n",
    "# tweets_df['media']= tweets_df['media'].apply(get_image_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T15:33:35.836339Z",
     "start_time": "2022-11-07T15:33:35.829596Z"
    },
    "scrolled": true,
    "tags": [
     "output_scroll",
     "full-width"
    ]
   },
   "outputs": [],
   "source": [
    "# HTML(tweets_df[['media', 'text']].sort_values(by='media').to_html(render_links=True, escape=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View tweet links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T15:33:36.515692Z",
     "start_time": "2022-11-07T15:33:36.510666Z"
    },
    "scrolled": true,
    "tags": [
     "full-width",
     "output_scroll"
    ]
   },
   "outputs": [],
   "source": [
    "# HTML(tweets_df[['tweet_url', 'text', 'retweets']].sort_values(by='retweets', ascending=False).to_html(render_links=True, escape=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyze hashtags in a tweet dataset, we can use the plugin [`twarc2 hashtags`](https://pypi.org/project/twarc-hashtags/), which requires a separate installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T15:33:39.757921Z",
     "start_time": "2022-11-07T15:33:37.266723Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: twarc-hashtags in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (0.0.5)\n",
      "Requirement already satisfied: twarc>=2.1.1 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from twarc-hashtags) (2.12.0)\n",
      "Requirement already satisfied: click<9,>=7 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from twarc>=2.1.1->twarc-hashtags) (8.1.3)\n",
      "Requirement already satisfied: click-config-file>=0.6 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from twarc>=2.1.1->twarc-hashtags) (0.6.0)\n",
      "Requirement already satisfied: humanize>=3.9 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from twarc>=2.1.1->twarc-hashtags) (3.13.1)\n",
      "Requirement already satisfied: tqdm>=4.62 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from twarc>=2.1.1->twarc-hashtags) (4.64.0)\n",
      "Requirement already satisfied: click-plugins>=1 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from twarc>=2.1.1->twarc-hashtags) (1.1.1)\n",
      "Requirement already satisfied: requests-oauthlib>=1.3 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from twarc>=2.1.1->twarc-hashtags) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from twarc>=2.1.1->twarc-hashtags) (2.8.2)\n",
      "Requirement already satisfied: configobj>=5.0.6 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from click-config-file>=0.6->twarc>=2.1.1->twarc-hashtags) (5.0.6)\n",
      "Requirement already satisfied: six>=1.5 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.8->twarc>=2.1.1->twarc-hashtags) (1.16.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=1.3->twarc>=2.1.1->twarc-hashtags) (2.28.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=1.3->twarc>=2.1.1->twarc-hashtags) (3.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.0.0->requests-oauthlib>=1.3->twarc>=2.1.1->twarc-hashtags) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.0.0->requests-oauthlib>=1.3->twarc>=2.1.1->twarc-hashtags) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.0.0->requests-oauthlib>=1.3->twarc>=2.1.1->twarc-hashtags) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/paschalis/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.0.0->requests-oauthlib>=1.3->twarc>=2.1.1->twarc-hashtags) (1.26.11)\n"
     ]
    }
   ],
   "source": [
    "!pip install twarc-hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can create a CSV digest of the top hashtags from our JSONL data with `twarc2 hashtags`. (To get more hashtag data, we are using a JSONL file that contains a full archive search of \"David Foster Wallace\" rather than \"David Foster Wallace bro\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T15:33:39.769217Z",
     "start_time": "2022-11-07T15:33:39.766986Z"
    }
   },
   "outputs": [],
   "source": [
    "# !twarc2 hashtags twitter-data/dfw.jsonl twitter-data/dfw_hashtags.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T15:33:39.779869Z",
     "start_time": "2022-11-07T15:33:39.777699Z"
    }
   },
   "outputs": [],
   "source": [
    "# pd.read_csv('twitter-data/dfw_hashtags.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the flag `--group` to group the hashtags by their frequency per time period and the flag `--limit` to limit the hashtags to only the top *n* number of hashtags per grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T15:33:39.787864Z",
     "start_time": "2022-11-07T15:33:39.784948Z"
    }
   },
   "outputs": [],
   "source": [
    "# !twarc2 hashtags --group year --limit 10 twitter-data/dfw.jsonl twitter-data/dfw_hashtags_year.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T15:33:44.237477Z",
     "start_time": "2022-11-07T15:33:44.233441Z"
    }
   },
   "outputs": [],
   "source": [
    "# hashtags_df = pd.read_csv('twitter-data/dfw_hashtags_year.csv')\n",
    "# hashtags_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To plot the frequency of hashtags over time, we can set the DataFrame index to the \"time\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T15:33:44.599608Z",
     "start_time": "2022-11-07T15:33:44.594706Z"
    }
   },
   "outputs": [],
   "source": [
    "# hashtags_df = hashtags_df.set_index('time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can filter for a specific hashtag and plot its frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T15:33:44.939559Z",
     "start_time": "2022-11-07T15:33:44.934649Z"
    }
   },
   "outputs": [],
   "source": [
    "# hashtags_df[hashtags_df['hashtag'] == 'writing'].plot(y='tweets', label='#writing', title='DFW Hashtags');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot multiple hashtags on the same plot by assigning the first plot to the variable `main_axis` and then directing the next plots to be plotted on the same axis `ax=main_axis`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T15:33:45.320523Z",
     "start_time": "2022-11-07T15:33:45.314275Z"
    }
   },
   "outputs": [],
   "source": [
    "# main_axis = hashtags_df[hashtags_df['hashtag'] == 'writing'].plot(y='tweets', label='#writing', title='DFW Hashtags')\n",
    "# hashtags_df[hashtags_df['hashtag'] == 'dfw'].plot(ax=main_axis, y='tweets', label='#dfw')\n",
    "# hashtags_df[hashtags_df['hashtag'] == 'infinitejest'].plot(ax=main_axis, y='tweets', label='#infinitejest');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See an example of running the English-language [sentiment analysis tool VADER on Donald Trump's tweets](../05-Text-Analysis/04-Sentiment-Analysis)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See an example of using [topic modeling on Donald Trump's tweets](../05-Text-Analysis/11-Topic-Modeling-Time-Series)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
